---
title: "Exercise 8.2: Housing Dataset"
author: "Katie Adams"
date: "25/04/2021"
output: pdf_document
---

```{r, include=TRUE}
library(tinytex)
knitr::opts_chunk$set(echo = TRUE)

## Load the `data/week-7-housing` and assign a variable
housing_df <- read.csv("C:/Users/kadams/OneDrive - Suncor Energy Inc/DSC Masters Program/GitHub/DSC520/Assignments/dsc520/data/week-7-housing.csv", header=TRUE)
head(housing_df)
```
## Housing Data
### Work individually on this assignment. You are encouraged to collaborate on ideas and strategies pertinent to this assignment. Data for this assignment is focused on real estate transactions recorded from 1964 to 2016 and can be found in Housing.xlsx. Using your skills in statistical correlation, multiple regression, and R programming, you are interested in the following variables: Sale Price and several other possible predictors.
### If you worked with the Housing dataset in previous week â€“ you are in luck, you likely have already found any issues in the dataset and made the necessary transformations. If not, you will want to take some time looking at the data with all your new skills and identifying if you have any clean up that needs to happen.
### Complete the following:
```{r, include=TRUE}
library(tinytex)
knitr::opts_chunk$set(echo = TRUE)

## Load the `data/week-7-housing` and assign a variable
housing_df <- read.csv("C:/Users/kadams/OneDrive - Suncor Energy Inc/DSC Masters Program/GitHub/DSC520/Assignments/dsc520/data/week-7-housing.csv", header=TRUE)
head(housing_df)
```
1. Explain any transformations or modifications you made to the dataset
- Sale Date and Sale Price fields: substituted space with _
- ctyname field: Blanks should be populated with appropriate city referencing the zip5 field (98052 is REDMOND, 98053 is REDMOND, 98059 is RENTON, and 98074 is SAMMAMISH)
- year_renovated field: values of 0 should be populated with "no"
- No total bath field
- Transform the data to log

2. Create two variables; one that will contain the variables Sale Price and Square Foot of Lot (same variables used from previous assignment on simple regression) and one that will contain Sale Price and several additional predictors of your choice. Explain the basis for your additional predictor selections.
- The reason I chose these additional predictors of Zip Code (zip5), Year Built (year_built), and the house square footage (square_feet_total_living) is because often times the sale price is dictated by the house location (Zip Code), the year it was built (year_built), and how big the house is (square_feet_total_living). 
```{r, include=TRUE}
sqftlt_lm <- lm(Sale_Price ~ sq_ft_lot, data = housing_df)
zip5_lm <- lm(Sale_Price ~ zip5 + year_built + square_feet_total_living, data = housing_df)
hist(log(housing_df$Sale_Price))
```
3. Execute a summary() function on two variables defined in the previous step to compare the model results. What are the R2 and Adjusted R2 statistics? Explain what these results tell you about the overall model. Did the inclusion of the additional predictors help explain any large variations found in Sale Price?
- For sqftlt_lm (single regression), Multiple R-squared:  0.01435,	Adjusted R-squared:  0.01428 
- For zip5_lm (multiple regression), Multiple R-squared:  0.2185,	Adjusted R-squared:  0.2183
- These results show that about 20% (20%ish) is explained by zip code, age of house and square feet. The inclusion of the additional predictors did help explain large variations in the sale Price (a bigger r2 means more variations explained in the model).
```{r, include=TRUE}
#View the summary of your model using `summary()`
summary(sqftlt_lm)$r.squared
summary(zip5_lm)$r.squared

summary(sqftlt_lm)$adj.r.squared
summary(zip5_lm)$adj.r.squared
```

4. Considering the parameters of the multiple regression model you have created. What are the standardized betas for each parameter and what do the values indicate?
- The standardized beta for zip is 1.096795, for year built is 13.808582, and square feet is 51.047880. The beta values indicate that when the variables increases, this is how much the Sales Price will increase.
```{r, include=TRUE}
beta_zip5 <- summary(zip5_lm)$coef[,3]
```
5. Calculate the confidence intervals for the parameters in your model and explain what the results indicate.
Assess the improvement of the new model compared to your original model (simple regression model) by testing whether this change is significant by performing an analysis of variance.
- The confidence interval of the single regression model is 0.1218624 
- The confidence intervals of the multiple regression model: zip5 is 3.672101e+03, year built is 3.779981e+02, and square feet is 6.572673e+00
- There is great improvement with the new model over the original model 
```{r, include=TRUE}
summary(sqftlt_lm)
summary(zip5_lm)

beta_sqftlt <- summary(sqftlt_lm)$coef[,3]

confidence_Interval_sqftlt <- 1.96*summary(sqftlt_lm)$coef[,2]
confidence_Interval_zip5 <- 1.96*summary(zip5_lm)$coef[,2]

upper_zip5 <- beta_zip5+confidence_Interval_zip5
lower_zip5 <- beta_zip5-confidence_Interval_zip5
```
6. Perform casewise diagnostics to identify outliers and/or influential cases, storing each function's output in a dataframe assigned to a unique variable name.
- Outliers are 2852, 4649, and 8262
```{r, include=TRUE}
plot(zip5_lm)
library(car)
# Influential Observations
# added variable plots
avPlots(zip5_lm)
# Cook's D plot
# identify D values > 4/(n-k-1)
cutoff <- 4/((nrow(housing_df)-length(zip5_lm$coefficients)-2))
plot(zip5_lm, which=4, cook.levels=cutoff)
# Influence Plot
influencePlot(zip5_lm, id.method="identify", main="Influence Plot", sub="Circle size is proportial to Cook's Distance" )
```
7. Calculate the standardized residuals using the appropriate command, specifying those that are +-2, storing the results of large residuals in a variable you create.
```{r, include=TRUE}
residuals <- rstandard(zip5_lm)

residuals_large <- residuals[abs(residuals)>2]

```
8. Use the appropriate function to show the sum of large residuals.
- 1242.848
```{r, include=TRUE}
sum(residuals_large)
```
9. Which specific variables have large residuals (only cases that evaluate as TRUE)?
- 
```{r, include=TRUE}
which(abs(residuals)>2)
```
10. Investigate further by calculating the leverage, cooks distance, and covariance rations. Comment on all cases that are problematics.
```{r, include=TRUE}
#leverage
hats<-as.data.frame(hatvalues(zip5_lm))
plot(hats, type='h')

# Cook's D plot
# added variable plots
avPlots(zip5_lm)
# identify D values > 4/(n-k-1)
cutoff <- 4/((nrow(housing_df)-length(zip5_lm$coefficients)-2))
plot(zip5_lm, which=4, cook.levels=cutoff)
# Influence Plot
influencePlot(zip5_lm, id.method="identify", main="Influence Plot", sub="Circle size is proportial to Cook's Distance" )

#covariance rations
vcov(zip5_lm)
```
11. Perform the necessary calculations to assess the assumption of independence and state if the condition is met or not.
- This rejects the null hypothesis and leading to the alternative hypothesis that there is an association with zip and year built.
```{r, include=TRUE}
chisq.test(table(housing_df$zip5, housing_df$year_built))
```
12. Perform the necessary calculations to assess the assumption of no multicollinearity and state if the condition is met or not.
- There is no multicollinearity as the numbers are small. 
```{r, include=TRUE}
vif(zip5_lm)
```
13. Visually check the assumptions related to the residuals using the plot() and hist() functions. Summarize what each graph is informing you of and if any anomalies are present.
- Residuals vs Fitted: no specific patterns, random throughout
- Normal Q-Q: the numbers should be a straight line, so we assume the model is not normal
- Scale-Location: The values all cluster at the left of the plot with the standard residuals going all the way up to 3.0
- Residuals vs Leverage: There are a lot of small values, and very large residuals creating clustering around the left (this is why log is required to reduce the effects of the residuals)
```{r, include=TRUE}
plot(zip5_lm)
```
14. Overall, is this regression model unbiased? If an unbiased regression model, what does this tell us about the sample vs. the entire population model?
- With the residual sum of 0.1498461 and with the visualizated information from the residuals boxplot, this is an unbias regression model which means that adding more data will not improve things and there a lot of variables from it. We don't need to increase the sample size because it won't make the sampling better. 
```{r, include=TRUE}
sum(residuals)
boxplot(residuals)
```